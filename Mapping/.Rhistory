filenames[intersect(grep(db, filenames),grep(".csv",filenames))]
filenames <- list.files(path, full.names = T)
filenames[intersect(grep(db, filenames),grep(".csv",filenames))]
rm(path, filenames)
clean.topics <- merge_topics(clean, "Topic_Data/")
source("SpatialUtil.R")
meters <- LongLatToM(clean$long,clean$lat,epsg)
map
map + theme(
axis.text.x = element_blank(),
axis.text.y = element_blank(),
axis.ticks = element_blank())
library(dplyr)
library(ggplot2)
library(ggmap)
map + theme(
axis.text.x = element_blank(),
axis.text.y = element_blank(),
axis.ticks = element_blank())
map + theme(axis.ticks = element_blank())
map <- ggmap(get_map(location = bbox, source = "stamen", maptype="toner", color = "bw")) +
theme(axis.text.x = element_blank(),
axis.text.y = element_blank(),
axis.ticks = element_blank())
map <- ggmap(get_map(location = bbox, source = "stamen", maptype="toner", color = "bw")) +
theme(axis.text.x = element_blank(),
axis.title.x = element_blank(),
axis.text.y = element_blank(),
axis.title.y = element_blank(),
axis.ticks = element_blank())
map
grid.points <- findN(map,200,epsg)
all_langs <- clean %>%
group_by(language) %>%
count() %>%
mutate(percent = n*100/sum(n)) %>%
arrange(desc(n))
map + scale_color_brewer(palette = "Set1") +
stat_chull(aes(x = long, y = lat, color = language),
data = clean %>%
filter(language %in% all_langs$language[1:6]), fill = NA)
?ggtitle
map + scale_color_brewer(palette = "Set1") +
stat_chull(aes(x = long, y = lat, color = language),
data = clean %>%
filter(language %in% all_langs$language[1:6]), fill = NA) +
ggtitle(paste("Convex Hull of Top 6 Languages in",db))
map + scale_color_brewer(palette = "Set1") +
stat_chull(aes(x = long, y = lat, color = language),
data = clean %>%
filter(source != "Instagram",language %in% all_langs$language[1:6]), fill = NA)+
ggtitle(paste("Convex Hull of Top 6 Languages in",db))
map + scale_color_brewer(palette = "Set1") +
stat_chull(aes(x = long, y = lat, color = language),
data = clean %>%
filter(source != "Instagram",language %in% all_langs$language[1:6]), fill = NA)+
ggtitle(paste("Convex Hull of Top 6 Languages in",db,"(No Instagram)"))
top_langs
table(clean.topics$source)
table(clean.topics %>% filter(!(source %in% c("Twitter for Windows", "altın dükkan twitter robotu"))) %>% select(source) %>% table
_)
table(clean.topics %>% filter(!(source %in% c("Twitter for Windows", "altın dükkan twitter robotu"))) %>% select(source))
merge_topics <- function(data, path){
require(readr)
require(dplyr)
# Obtain a list of all files in the path
filenames <- list.files(path = path, full.names = T)
# For each .csv file in the above which contains the "db" variable (sourced from the
# metadata file), read the file and insert the data frame into a list.
data.list <- lapply(filenames[intersect(grep(db, filenames),grep(".csv",filenames))],
function(x){read_csv(x)} %>%
select(user_id, user_language, top_topic, topic_prob))
# return all of the topics for a given locale.
temp.topics <- Reduce(function(x,y){rbind(x,y)},data.list)
# Join the topics with the data
temp <- left_join(data, temp.topics, by = "user_id")
# Create a new feature, "lang.topic", which combines a user's language with
# the corresponding topic if it exists. If not, returns the user's language.
temp$lang.topic <- ifelse(is.na(temp$user_language),
as.character(temp$language),
paste("Topic",temp$top_topic,"-",temp$user_language))
temp %>%
filter(!(source %in% c("Twitter for Windows", "altın dükkan twitter robotu")))
}
clean.topics <- merge_topics(clean, "Topic_Data/")
table(clean.topics$source)
meters <- LongLatToM(clean$long,clean$lat,epsg)
topic_meters <- cbind(clean,meters)
save.image("~/Box Sync/Capstone Files/Cultural_Mapper/Mapping/Data/ISTData.RData")
all_langs <- clean.topics %>%
group_by(language) %>%
count() %>%
mutate(percent = n*100/sum(n)) %>%
arrange(desc(n))
map + scale_color_brewer(palette = "Set1") +
stat_chull(aes(x = long, y = lat, color = language),
data = clean %>%
filter(language %in% all_langs$language[1:6]), fill = NA) +
ggtitle(paste("Convex Hull of Top 6 Languages in",db))
map + scale_color_brewer(palette = "Set1") +
stat_chull(aes(x = long, y = lat, color = language),
data = clean.topics %>%
filter(language %in% all_langs$language[1:6]), fill = NA) +
ggtitle(paste("Convex Hull of Top 6 Languages in",db))
?png
plot(1:10)
example(rect)
temp <- map + scale_color_brewer(palette = "Set1") +
stat_chull(aes(x = long, y = lat, color = language),
data = clean.topics %>%
filter(language %in% all_langs$language[1:6]), fill = NA) +
ggtitle(paste("Convex Hull of Top 6 Languages in",db))
temp
png(temp,file = paste0(db,"%d.png"), width = 500, height = 500)
png(temp,file = paste0(db,"%d.png"), width = 500, height = 500, units = "px")
dev.off()
paste0(db,"%d.png")
?dev.off
png(temp,file = paste0(db,"%d.png"), width = 500, height = 500, units = "px")
png(temp, file = "test.png")
temp
temp <- map + scale_color_brewer(palette = "Set1") +
stat_chull(aes(x = long, y = lat, color = language),
data = clean.topics %>%
filter(language %in% all_langs$language[1:6]), fill = NA) +
ggtitle(paste("Convex Hull of Top 6 Languages in",db))
temp
dev.off()
dev.off()
dev.off()
temp
temp <- map + scale_color_brewer(palette = "Set1") +
stat_chull(aes(x = long, y = lat, color = language),
data = clean.topics %>%
filter(language %in% all_langs$language[1:6]), fill = NA) +
ggtitle(paste("Convex Hull of Top 6 Languages in",db))
png(temp,file = paste0(db,"%d.png"), width = 500, height = 500, units = "px")
dev.off()
dev.off()
temp
temp <- map + scale_color_brewer(palette = "Set1") +
stat_chull(aes(x = long, y = lat, color = language),
data = clean.topics %>%
filter(language %in% all_langs$language[1:6]), fill = NA) +
ggtitle(paste("Convex Hull of Top 6 Languages in",db))
temp
temp <- map + scale_color_brewer(palette = "Set1") +
stat_chull(aes(x = long, y = lat, color = language),
data = clean.topics %>%
filter(source != "Instagram",language %in% all_langs$language[1:6]), fill = NA)+
ggtitle(paste("Convex Hull of Top 6 Languages in",db,"(No Instagram)"))
temp
top_langs
temp <- map + scale_color_brewer(palette = "Set1") +
stat_chull(aes(x = as.numeric(long), y = as.numeric(lat), color = as.factor(top_topic)),
data = clean.topics %>% filter(top_topic %in% top_langs[0:6]), fill = NA) +
ggtitle(paste("Convex Hull of Top 6 Languages in",db,"(No Instagram)"))
temp <- map + scale_color_brewer(palette = "Set1") +
stat_chull(aes(x = as.numeric(long), y = as.numeric(lat), color = as.factor(top_topic)),
data = clean.topics %>% filter(top_topic %in% top_langs$lang.topic[0:6]), fill = NA) +
ggtitle(paste("Convex Hull of Top 6 Languages in",db,"(No Instagram)"))
temp <- map + scale_color_brewer(palette = "Set1") +
stat_chull(aes(x = as.numeric(long), y = as.numeric(lat), color = as.factor(top_topic)),
data = clean.topics %>% filter(top_topic %in% top_langs$lang.topic[0:6]), fill = NA) +
ggtitle(paste("Convex Hull of Top 6 Topics in",db,"(No Instagram)"))
temp
temp <- map + scale_color_brewer(palette = "Set1") +
stat_chull(aes(x = as.numeric(long), y = as.numeric(lat), color = as.factor(top_topic)),
data = clean.topics %>% filter(lang.topic %in% top_langs$lang.topic[0:6]), fill = NA) +
ggtitle(paste("Convex Hull of Top 6 Topics in",db,"(No Instagram)"))
temp
temp <- map + scale_color_brewer(palette = "Set1") +
stat_chull(aes(x = as.numeric(long), y = as.numeric(lat), color = as.factor(lang.topic)),
data = clean.topics %>% filter(lang.topic %in% top_langs$lang.topic[0:6]), fill = NA) +
ggtitle(paste("Convex Hull of Top 6 Topics in",db,"(No Instagram)"))
temp
clean.topics %>% head
top_langs$lang.topic[0:6]
unique(clean.topics$top_topic)
strsplit(clean.topics$top_topic[1],"_")
strsplit(clean.topics$top_topic[1],"_")[[2]]
strsplit(clean.topics$top_topic[1],"_")[2]
strsplit(clean.topics$top_topic[1],"_")[[1]][2]
??stringr
?grep
grepl("[0-9]+",clean.topics$top_topic[1])
regexpr("[0-9]+",clean.topics$top_topic[1])
gregexpr("[0-9]+",clean.topics$top_topic[1])
gsub("[0-9]+",clean.topics$top_topic[1])
regexec("[0-9]+",clean.topics$top_topic[1])
gsub("\D","",clean.topics$top_topic[1])
regexec("\[0-9]+",clean.topics$top_topic[1])
regexec("/[0-9]+",clean.topics$top_topic[1])
regexec("/D",clean.topics$top_topic[1])
gsub("/D","",clean.topics$top_topic[1])
gsub("/\D","",clean.topics$top_topic[1])
library(stringr)
str_extract(clean.topics$top_topic[1],"[0-9]+")
str_extract(clean.topics$top_topic[1:10],"[0-9]+")
top_langs <- clean.topics %>% group_by(lang.topic) %>%
count() %>%
mutate(percent = 100*n/sum(n)) %>%
arrange(desc(percent))
temp <- map + scale_color_brewer(palette = "Set1") +
stat_chull(aes(x = as.numeric(long), y = as.numeric(lat), color = as.factor(lang.topic)),
data = clean.topics %>% filter(lang.topic %in% top_langs$lang.topic[0:6]), fill = NA) +
ggtitle(paste("Convex Hull of Top 6 Topics in",db,"(No Instagram)"))
temp
map + scale_color_brewer(palette = "Set1") +
geom_density2d(aes(x = long, y = lat, color = lang.topic),
n = grid.points,
data = clean.topics %>% filter(source != "Instagram",
language %in% top_langs$lang.topic[1:6])) +
facet_grid(day ~ hour.cut)
unique(clean.topics$hour.cut)
unique(clean.topics$day)
map + scale_color_brewer(palette = "Set1") +
geom_density2d(aes(x = long, y = lat, color = lang.topic),
n = grid.points,
data = clean.topics %>% filter(source != "Instagram",
lang.topic %in% top_langs$lang.topic[1:6])) +
facet_grid(day ~ hour.cut)
paste("Topic",str_extract(clean.topics$top_topic[10],"[0-9]+"),"-",temp$user_language))
paste("Topic",str_extract(clean.topics$top_topic[10],"[0-9]+"),"-",temp$user_language)
paste("Topic",str_extract(clean.topics$top_topic[10],"[0-9]+"),"-",temp$user_language[10])
temp
rm(temp)
paste("Topic",str_extract(clean.topics$top_topic[10],"[0-9]+"),"-",clean.topics$user_language[10])
temp <- map + scale_color_brewer(palette = "Set1") +
stat_chull(aes(x = as.numeric(long), y = as.numeric(lat), color = lang.topic),
data = clean.topics %>% filter(lang.topic %in% top_langs$lang.topic[0:6]), fill = NA) +
ggtitle(paste("Convex Hull of Top 6 Topics in",db,"(No Instagram)"))
temp
clean.topics %>% head
temp <- map + stat_density2d(aes(x = long, y = lat),
data = clean.topics %>% filter(user_language == "Turkish",
source != "Instagram")) +
facet_wrap( ~ day, nrow = 2) +
# English density by day of the week
temp <- map + stat_density2d(aes(x = long, y = lat,
fill = ..level..),
data = clean.topics%>%
filter(user_language == "English",
source != "Instagram"))# +
temp <- map + stat_density2d(aes(x = long, y = lat),
data = clean.topics %>% filter(user_language == "Turkish",
source != "Instagram")) +
facet_wrap( ~ day, nrow = 2) +
# English density by day of the week
temp <- map + stat_density2d(aes(x = long, y = lat,
fill = ..level..),
data = clean.topics %>%
filter(user_language == "English",
source != "Instagram"))# +
temp <- map + stat_density2d(aes(x = long, y = lat),
data = clean.topics %>% filter(user_language == "Turkish",
source != "Instagram")) +
facet_wrap( ~ day, nrow = 2) +
# English density by day of the week
temp <- map + stat_density2d(aes(x = long, y = lat,
fill = ..level..), geom = "polygon",
data = clean.topics %>%
filter(user_language == "English",
source != "Instagram"))# +
temp <- map + stat_density2d(aes(x = long, y = lat),
data = clean.topics %>% filter(user_language == "Turkish",
source != "Instagram")) +
facet_wrap( ~ day, nrow = 2) +
# English density by day of the week
temp <- map + stat_density2d(aes(x = long, y = lat,
fill = ..level..), geom = "polygon",
data = clean.topics %>%
filter(user_language == "English",
source != "Instagram"))
stat_density2d(aes(x = long, y = lat,
fill = ..level..), geom = "polygon",
data = clean.topics %>%
filter(user_language == "English",
source != "Instagram"))
map + stat_density2d(aes(x = long, y = lat,
fill = ..level..), geom = "polygon",
data = clean.topics %>%
filter(user_language == "English",
source != "Instagram"))
temp <- map + stat_density2d(aes(x = long, y = lat),
data = clean.topics %>% filter(user_language == "Turkish",
source != "Instagram")) +
facet_wrap( ~ day, nrow = 2) +
# English density by day of the week
temp <- map + stat_density2d(aes(x = long, y = lat,
fill = ..level..), geom = "polygon",
data = clean.topics %>%
filter(user_language == "English",
source != "Instagram"))
temp <- map + scale_color_brewer(palette = "Set1") +
stat_chull(aes(x = long, y = lat, color = language),
data = clean.topics %>%
filter(source != "Instagram",language %in% all_langs$language[1:6]), fill = NA)+
ggtitle(paste("Convex Hull of Top 6 Languages in",db,"(No Instagram)"))
temp <- map + stat_density2d(aes(x = long, y = lat),
data = clean.topics %>% filter(user_language == "Turkish",
source != "Instagram")) +
facet_wrap( ~ day, nrow = 2) +
# English density by day of the week
map + stat_density2d(aes(x = long, y = lat,
fill = ..level..), geom = "polygon",
data = clean.topics %>%
filter(user_language == "English",
source != "Instagram"))
temp <- map + stat_density2d(aes(x = long, y = lat),
data = clean.topics %>% filter(user_language == "Turkish",
source != "Instagram")) +
facet_wrap( ~ day, nrow = 2) +
# English density by day of the week
map + stat_density2d(aes(x = long, y = lat,
fill = ..level..), geom = "polygon",
data = clean.topics %>%
filter(user_language == "English",
source != "Instagram"))
temp <- map + stat_density2d(aes(x = long, y = lat),
data = clean.topics %>% filter(user_language == "Turkish",
source != "Instagram")) +
facet_wrap( ~ day, nrow = 2) +
# English density by day of the week
map + stat_density2d(aes(x = long, y = lat,
fill = ..level..), geom = "polygon",
data = clean.topics %>%
filter(user_language == "English",
source != "Instagram"))
map <- ggmap(get_map(location = bbox, source = "stamen", maptype="toner", color = "bw"))
temp <- map + stat_density2d(aes(x = long, y = lat),
data = clean.topics %>% filter(user_language == "Turkish",
source != "Instagram")) +
facet_wrap( ~ day, nrow = 2) +
# English density by day of the week
map + stat_density2d(aes(x = long, y = lat,
fill = ..level..), geom = "polygon",
data = clean.topics %>%
filter(user_language == "English",
source != "Instagram"))
temp <- map + stat_density2d(aes(x = long, y = lat),
data = clean.topics %>% filter(user_language == "Turkish",
source != "Instagram")) +
facet_wrap( ~ day, nrow = 2) +
# English density by day of the week
map + stat_density2d(aes(x = long, y = lat, fill = ..level..), geom = "polygon",
data = clean.topics[1:2000,])
map + geom_point(aes(x = long, y = lat), data = clean %>% filter(language =="Turkish", hour.cut == "9pm-12am"))
map + geom_point(aes(x = long, y = lat), data = clean.topics %>% filter(language =="Turkish", hour.cut == "9pm-12am"))
map + geom_point(aes(x = long, y = lat), data = clean.topics %>% filter(user_lang =="Turkish", hour.cut == "9pm-12am"))
head(clean.topics)
levels(clean.topics$hour.cut)
map + geom_point(aes(x = long, y = lat), data = clean.topics %>%
filter(user_language =="Turkish", hour.cut == "8pm-12am"))
m <- ggplot(faithful, aes(x = eruptions, y = waiting)) +
geom_point() +
xlim(0.5, 6) +
ylim(40, 110)
m + stat_density_2d(aes(fill = ..level..), geom = "polygon")
ggplot() + stat_density2d(aes(x = long, y = lat,
fill = ..level..), geom = "polygon",
data = clean.topics %>%
filter(user_language == "English",
source != "Instagram"))
map + stat_density2d(aes(x = long, y = lat,
fill = ..level..), geom = "polygon",
data = clean.topics %>%
filter(user_language == "English",
source != "Instagram"))
map + stat_density2d(aes(x = long, y = lat,
fill = ..level..), geom = "polygon",
data = clean.topics %>%
filter(user_language == "English",
source != "Instagram")) +
theme(axis.text.x = element_blank(),
axis.title.x = element_blank(),
axis.text.y = element_blank(),
axis.title.y = element_blank(),
axis.ticks = element_blank())
map <- ggmap(get_map(location = bbox, source = "stamen", maptype="toner", color = "bw")) +
theme(axis.text.x = element_blank(),
axis.title.x = element_blank(),
axis.text.y = element_blank(),
axis.title.y = element_blank(),
axis.ticks = element_blank())
map
map + stat_density2d(aes(x = long, y = lat,
fill = ..level..), geom = "polygon",
data = clean.topics %>%
filter(user_language == "English",
source != "Instagram")) +
theme(axis.text.x = element_blank(),
axis.title.x = element_blank(),
axis.text.y = element_blank(),
axis.title.y = element_blank(),
axis.ticks = element_blank())
map + stat_density2d(aes(x = long, y = lat,
fill = ..level..), geom = "polygon",
data = clean.topics %>%
filter(user_language == "English",
source != "Instagram"))
map + stat_density2d(aes(x = long, y = lat,
fill = ..level..), geom = "polygon",
data = clean.topics %>%
filter(user_language == "English",
source != "Instagram"))+scale_fill_distiller(palette = "Spectral")
temp <- map + stat_density2d(aes(x = long, y = lat),
data = clean.topics %>% filter(user_language == "Turkish",
source != "Instagram")) +
facet_wrap( ~ day, nrow = 2) +
# English density by day of the week
map + stat_density2d(aes(x = long, y = lat,
fill = ..level..), geom = "polygon",
data = clean.topics %>%
filter(user_language == "English",
source != "Instagram")) +
#facet_wrap(~ day, nrow = 2) +
scale_fill_distiller(palette = "Spectral")
temp <- map + stat_density2d(aes(x = long, y = lat),
data = clean.topics %>% filter(user_language == "Turkish",
source != "Instagram")) +
facet_wrap( ~ day, nrow = 2) +
# English density by day of the week
map + stat_density2d(aes(x = long, y = lat,
fill = ..level..), geom = "polygon",
data = clean.topics %>%
filter(user_language == "English",
source != "Instagram")) +
#facet_wrap(~ day, nrow = 2) +
scale_fill_distiller(palette = "Spectral")
map + stat_density2d(aes(x = long, y = lat,
fill = ..level..), geom = "polygon",
data = clean.topics %>%
filter(user_language == "English",
source != "Instagram")) +
scale_fill_distiller(palette = "Spectral")
temp <- map + stat_density2d(aes(x = long, y = lat),
data = clean.topics %>% filter(user_language == "Turkish",
source != "Instagram")) +
facet_wrap( ~ day, nrow = 2) +
# English density by day of the week
map + stat_density2d(aes(x = long, y = lat,
fill = ..level..), geom = "polygon",
data = clean.topics %>%
filter(user_language == "English",
source != "Instagram")) +
facet_wrap(~ day, nrow = 2) +
scale_fill_distiller(palette = "Spectral")
map + stat_density2d(aes(x = long, y = lat,
fill = ..level..), geom = "polygon",
data = clean.topics %>%
filter(user_language == "English",
source != "Instagram")) +
facet_wrap(~ day, nrow = 2) +
scale_fill_distiller(palette = "Spectral")
map + stat_density2d(aes(x = long, y = lat,
fill = ..level..), geom = "polygon",
data = clean.topics %>%
filter(user_language == "English",
source != "Instagram")) +
facet_wrap(~ day, nrow = 2) +
scale_fill_distiller(palette = "Spectral") +
ggtitle(paste("English Tweets in",db,"by Day"))
clean.topics %>% group_by(user_language) %>% count
langs <- clean.topics %>%
group_by(user_language) %>%
count() %>%
mutate(percent = 100*n/sum(n)) %>%
arrange(desc(percent))
langs
langs$user_language[1]
temp <- map + stat_density2d(aes(x = long, y = lat),
data = clean.topics %>% filter(user_language == "Turkish",
source != "Instagram")) +
facet_wrap( ~ day, nrow = 2) +
# English density by day of the week
map + stat_density2d(aes(x = long, y = lat,
fill = ..level..), geom = "polygon",
data = clean.topics %>%
filter(user_language == langs$user_language[2],
source != "Instagram")) +
facet_wrap(~ day, nrow = 2) +
scale_fill_distiller(palette = "Spectral") +
ggtitle(paste(langs$user_language[2],"Tweets in",db,"by Day"))
map + stat_density2d(aes(x = long, y  = lat,
fill = ..level..), geom = "polygon",
n = grid.points,
data = clean %>% filter(language == langs$user_language[1],
source != "Instagram",
hour %in% c(21,22,23))) +
facet_wrap(~ hour.cut, nrow = 2) +
scale_fill_distiller(palette = "Spectral") +
ggtitle(paste(langs$user_language[1],"Tweets in",db,"by Day by Hour"))
map + geom_point(aes(x=long, y=lat, color = "red"),
data = clean %>% filter(language == "Turkish",
source != "Instagram",
hour == 0))
temp <- map + geom_point(aes(x=long, y=lat, color = "red"),
data = clean %>% filter(language == "Turkish",
source != "Instagram",
hour == 0))
png(temp, filename = "test%d.png")
png(temp, filename = "test%d.png", height = 200, width = 200, unit ="px")
temp
dev.off()
dev.off()
pdf("test.pdf")
map + geom_point(aes(x=long, y=lat, color = "red"),
data = clean %>% filter(language == "Turkish",
source != "Instagram",
hour == 0))
dev.off()
