source("Postgres_functions.R")
source("SpatialUtil.R")
source("IST_meta.R")
con <- connectDB(db)
loc.data = dbGetQuery(con, paste0("
WITH casted AS(
SELECT id, CAST(created_at as timestamptz) as created_at, source, text_lang, user_id,
user_lang
FROM ",db,"_city_primary
WHERE source ILIKE ANY(ARRAY['%for Blackberry%', '%for Android%', '%tron%',
'%Foursquare%','%Instagram%','%for iOS%',
'%for iPhone%','%for Windows Phone%',
'%for iPad%','Twitter Web Client','%for Mac%'])
)
SELECT timezone('",tz,"',created_at) as tzone,
text_lang, user_lang, user_id, source
FROM casted
WHERE timezone('",tz,"',created_at) > '2016-10-28' AND
timezone('",tz,"',created_at) < '2017-01-28';"))
# Disconnect
disconnectDB(con)
library(dplyr)
library(lubridate)
clean <- merge_langs(loc.data)
clean <- merge_langs(loc.data)
View(merge_langs)
registry <- load_langs()
data_merge <- left_join(loc.data, registry)
data_merge$language <- as.factor(data_merge$language)
data_merge %>%
mutate(source = gsub(pattern = "<.+\">|</a>", "",source))
format(head(data_merge$tz), "%d %b %Y")
data_merge <- data_merge %>%
mutate(source = gsub(pattern = "<.+\">|</a>", "",source),
date= format(tz, "%d %b %Y"))
names(data_merge)
names(loc.data)
data_merge <- data_merge %>%
mutate(source = gsub(pattern = "<.+\">|</a>", "",source),
date= format(tzone, "%d %b %Y"))
rm(registry, loc.data)
clean.topics <- merge_topics(data_merge, "Topic_Data/")
rm(data_merge)
save.image("~/Cultural_Mapper/AWSTimeSeries/RData/IST.RData")
names(clean.topics)
head(clean.topics)
is.Date(clean.topics$date)
as.Date(clean.topics$date[1])
?as.Date
as.Date(clean.topics$date[1],"%d %b %Y")
as.Date(clean.topics$date[1:10],"%d %b %Y")
clean.topics %>%
mutate(date = as.Date(date,"%d %b %Y")) %>%
group_by(date, lang.topic) %>% count
registry <- load_langs()
setdiff(registry$language, unique(clean.topics$lang.topic))
?setdiff
intersect(registry$language, unique(clean.topics$lang.topic))
!(lang.topic %in% registry$language)
!(clean.topics$lang.topic %in% registry$language)
!(head(clean.topics$lang.topic) %in% registry$language)
head(clean.topics$lang.topic)
# Aggregate count by date and topic
clean.topics %>%
mutate(date = as.Date(date,"%d %b %Y")) %>%
filter(!(lang.topic %in% registry$language)) %>%
group_by(date, lang.topic) %>% count
library(tidyr)
counts <- clean.topics %>%
mutate(date = as.Date(date,"%d %b %Y")) %>%
filter(!(lang.topic %in% registry$language)) %>%
group_by(date, lang.topic) %>% count
?spread
counts %>% spread %>% head
counts %>% spread(date,n) %>% head
counts %>% spread(lang.topic,n) %>% head
arrange(desc(date)) %>% head
arrange(date) %>% head
arrange(`date`) %>% head
counts %>%
spread(lang.topic,n) %>%
arrange(`date`) %>% head
counts %>%
spread(lang.topic,n) %>%
arrange(date) %>% head
counts <- counts %>%
counts <- counts %>%
spread(lang.topic,n) %>%
arrange(date) %>% head
counts <- clean.topics %>%
mutate(date = as.Date(date,"%d %b %Y")) %>%
filter(!(lang.topic %in% registry$language)) %>%
group_by(date, lang.topic) %>% count
counts <- counts %>%
spread(lang.topic,n) %>%
arrange(date)
plot.ts(counts$date,counts$`Topic 0 - Turkish`)
ts(counts$`Topic 0 - English`)
save.image("~/Cultural_Mapper/AWSTimeSeries/RData/IST.RData")
ts.test <- ts(counts$`Topic 0 - English`)
plot(ts.test)
plot(stl(ts.test), "per")
ts.test <- ts(counts$`Topic 0 - English`, freq  = 7)
plot(ts.test)
plot(stl(ts.test), "per")
?stl
plot(stl(ts.test), "periodic")
plot(stl(ts.test, "per"))
acf(ts.test)
pacf(ts.test)
lag.plot(ts.test)
lag.plot(ts.test, lags = 7)
library(forecast)
?auto.arima
fit <- auto.arima(ts.test)
fit
Acf(fit)
Acf(ts.test)
Acf(ts.test)
Pacf(ts.test)
Ccf(ts.test)
Ccf(ts.test, ts.test)
ts.test2 <- ts(counts$`Topic 0 - Turkish`, freq  = 7)
Ccf(ts.test, ts.test2)
ts.test3 <- ts(counts$`Topic 1 - Turkish`, freq  = 7)
Ccf(ts.test, ts.test2, ts.test3)
Ccf(ts.test, ts.test2)
Ccf(ts.test3, ts.test2)
smooth(ts.test)
plot(smooth(ts.test))
lines(ksmooth(1:length(ts.test),ts.test))
plot(ts.test)
lines(ksmooth(1:length(ts.test),ts.test))
lines(ksmooth(1:length(ts.test),ts.test,'normal', bandwidth = 7))
lines(ksmooth(1:length(ts.test),ts.test,'normal', bandwidth = 7, col = 'Blue'))
lines(ksmooth(1:length(ts.test),ts.test,'normal', bandwidth = 7, col = 'blue'))
lines(ksmooth(1:length(ts.test),ts.test,'normal', bandwidth = 7), col = 'blue')
plot(ts.test)
lines(ksmooth(1:length(ts.test), ts.test, 'normal', bandwidth = 1), col = 'blue', lty = 2)
lines(ksmooth(1:length(ts.test), ts.test, 'normal', bandwidth = 4), col = 'red', lty = 2)
lines(ksmooth(1:length(ts.test), ts.test, 'normal', bandwidth = 7), col = 'green', lty = 2)
legend("topleft", c('Un-smoothed','Undersmoothed (5)', 'Smoothed (25)', 'Oversmoothed (100)'),
plot(ts.test)
lines(ksmooth(1:length(ts.test), ts.test, 'normal', bandwidth = 4), col = 'red', lty = 2)
plot(ts.test)
lines(ksmooth(1:length(ts.test), ts.test, 'normal', bandwidth = 4), col = 'red', lty = 2)
plot(stl(ts.test, "per"))
trend = ma(ts.test,order = 7, centre = T)
plot(ts.test)
lines(trend)
plot(ts.test - trend)
Ccf(ts.test3, ts.test2)
plot(fit$residuals)
scatter.smooth(fit$residuals)
rstudent(fit)
rstandard(fit)
install.packages("TSA")
rstandard(fit)
library(TSA)
rstandard(fit)
scatter.smooth(rstandard(fit))
Pacf(ts.test2)
Acf(ts.test2)
lag.plot(ts.test, lags = 7)
fit <- auto.arima(ts.test2)
fit
scatter.smooth(fit2$residuals)
scatter.smooth(fit$residuals)
scatter.smooth(rstandard(fit))
?TSA
?auto.arima
ts.test <- ts(counts$`Topic 0 - English`)
auto.arima(ts.test)
auto.arima(ts.test, max.D = 7)
auto.arima(ts.test, max.D = 7, trace = T)
adf.test(ts.test)
adf.test(ts.test,1)
adf.test(ts.test,k =1)
adf.test(ts.test)
adf.test(ts.test, k = 1:7)
adf.test(ts.test, k = 1)
adf.test(ts.test, k = 2)
adf.test(ts.test, k = 3)
adf.test(ts.test, k = 4)
adf.test(ts.test, k = 5)
nsdiffs(ts.test)
nsdiff(ts.test)
ndiff(ts.test)
ndiffs(ts.test)
ndiffs(ts.test2)
ndiffs(ts.test3)
auto.arima(ts.test3)
auto.arima(ts.test1)
auto.arima(ts.test)
ts.test <- ts(counts$`Topic 0 - English`, freq = 7)
ts.test2 <- ts(counts$`Topic 0 - Turkish`, freq  = 7)
ts.test3 <- ts(counts$`Topic 1 - Turkish`, freq  = 7)
ndiffs(ts.test3)
auto.arima(ts.test)
auto.arima(ts.test2)
Ccf(ts.test2, ts.test3)
Ccf(ts.test, ts.test3)
Ccf(diff(ts.test), ts.test3)
ndiffs(ts.test)
?ndiffs
nsdiffs(ts.test)
ts.test <- ts(counts$`Topic 0 - English`, freq = 7)
ts.test2 <- ts(counts$`Topic 0 - Turkish`, freq  = 7)
ts.test3 <- ts(counts$`Topic 1 - Turkish`, freq  = 7)
nsdiffs(ts.test)
ndiffs(ts.test)
nsdiffs(ts.test2)
install.packages("astsa")
